[
  {
    "objectID": "posts/helloworld/index.html",
    "href": "posts/helloworld/index.html",
    "title": "Hello world",
    "section": "",
    "text": "Quarto\nOne reason why I got tempted to start a blog again is Quarto! Quarto is the shiny, new publishing framework (from RStudioPosit) that I use to publish this blog. Quarto is reminiscent of Rmarkdown, but rebuilt around the pandoc engine. Quarto feels purpose built for the entire data community, supporting all the major Data Science languages (Python, R, Julia, Javascript), and supporting a wide spectrum of output formats (pdf reports, websites, presentations and more).\nYou can see my unbridled enthusiasm after first learning about Quarto here.\n\n\n\n\n\n\n‚Ä¶along with my ‚Äúthis-is-a-huge-moment-in-history‚Äù hyperbole\n\n\nJumpstarting this blog\nThese were the best resources I found online to help me jump start this blog.\n\n1. Official Quarto Documentation (website and repos)\nThe official docs are extensive and well-written. Specific to building a blog, I frequently find myself on the website page, publishing page or thumbing through their gallery for inspiration.\n\n\n2. Danielle Navarro‚Äôs ‚ÄúPorting a Distill Blog to Quarto‚Äù (blog and repo)\nDanielle‚Äôs blog post is the perfect starting template. I found her recommended YAML settings, blog theme and deployment instructions very sensible and well-suited for a blog.\n\n\n3. The small but growing collection of Quarto content online\nAt the time of writing, I did not find a large collection of Quarto-specific content online. Nevertheless, I did find some helpful gems from Youtube videos, Github discussions or websites that had a helpful tip or two that I could use for my blog.\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{tan2022,\n  author = {Daniel Tan},\n  title = {Hello World},\n  date = {2022-07-15},\n  url = {https://www.ddanieltan.com/posts/helloworld},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDaniel Tan. 2022. ‚ÄúHello World.‚Äù July 15, 2022. https://www.ddanieltan.com/posts/helloworld."
  },
  {
    "objectID": "posts/some2/index.html",
    "href": "posts/some2/index.html",
    "title": "Explainers: Inverse Transform Theorem",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nset.seed(sum(utf8ToInt(\"SoME2\")))\n\n\n\nWorlds at our fingertips\nModern day computers are pretty amazing simulation machines.\nHere‚Äôs an example. Say that I am a Bottle Flipping enthusiast and I am eager to simulate 100 bottle flips. To simulate flipping a bottle 100 times, I could instruct my computer to provide 100 simulations. At a technical level, I am modelling bottle flipping as a binomial distribution, and for my simulation I am generating 100 random variates from that distribution.\n\n\nCode\ntotalFlips = 100\nprob = 0.2 # Took me 5 tries to flip the bottle once\nrbinom(totalFlips, 1, prob) # 1 represents a successful flip\n\n\n  [1] 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0\n [38] 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n [75] 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n\n\n\n\nYes, üôÑ I know bottle flipping was a trend way back in 2016. I needed a success/failure example and it was either this of ‚Äúcoin flips‚Äù which I could not bring myself to use\nOr, say I‚Äôm a sports fan and my football team scores an average of 1 goal per game. I could simulate the goals scored over 100 games, by modelling the goals scored by my team after a Poisson distribution, and once again, run my simulation by generating 100 random variates from this distribution.\n\n\nCode\ntotalGames=100\navgGoalsPerGame = 1\nrpois(totalGames,avgGoalsPerGame)\n\n\n  [1] 0 1 2 1 2 2 0 0 1 2 2 0 1 0 1 3 2 2 1 1 2 1 1 1 1 0 4 3 1 0 0 0 2 1 0 1 0\n [38] 0 2 2 1 0 3 1 3 0 0 0 1 1 2 2 1 2 2 0 2 2 0 0 0 1 0 0 2 1 1 2 2 0 3 0 0 0\n [75] 0 0 0 1 1 2 1 2 0 1 3 1 2 0 0 2 2 0 2 1 0 0 2 2 1 1\n\n\nYou get the gist. From models using a single distribution to ones using complex combinations of distributions, our ability to generate random variates allows us to simulate almost any scenario we can think of!\n\n\nHow random variates are generated\nBut, how do computers even produce these random variates? Surely, there can‚Äôt be a specialised function for every one of the infinite distributions out in the world. It turns out that computers have a very simple solution in the form of two ingredients - a pseudorandom uniform generator and the inverse transform theorem.\nA pseudoranom uniform generator is an algorithm that produces random variates from a \\(Unif~(0,1)\\) distribution, producing uniformly random numbers between 0 and 1. There are many different algorithms that can produce uniform random variates and they are judged on how well they can come close to a perfectly random generator. The assortment of different uniform generators each with their pros and cons are interesting, but that will not be the focus of today‚Äôs post. Today, I want to focus on the 2nd ingredient, the inverse transform theorem.\n\n\nInverse Transform Theorem\nThe Inverse Transform Theorem is the backbone behind Inverse Transform Sampling, and is how a uniform distribution is transformed to a diverse range of other distributions.\nMy biggest challenge when I first encountered this theorem was to grasp the key idea behind its simplicity. Here is the theorem:\n\nLet \\(X\\) be a continuous random variable with c.d.f \\(F(x)\\). Then \\(F(X) \\sim Unif(0,1)\\).\n\nAnd, here‚Äôs the equally perplexing simple proof:\n\nLet \\(Y = F(X)\\) and suppose that \\(Y\\) has a c.d.f \\(G(y)\\), then \\[G(y) = P(Y \\leq y) = P(F(Y) \\leq y) \\] \\[ = P(X \\leq F^{-1}(y)) = F(F^{-1}(y)) = y\\]\n\nLet me explain the mechanics of the theorem. This theorem simply states that given we have a cumulative density function of a continuous random variable, the inverse of the CDF function will produce a Uniform distribution. While the usage of the theorem reads like a straight forward recipe, I had so many questions about why the theorem works:\n\nWhy is the theorem and proof so simple?\nHow could this theorem be universally true for any distribution?\nWhy did the theorem introduce the cumulative density function seemingly out of nowhere?\n\n\n\nVisual connection\nAnd what I see as a recurring theme amongst SoME submissions, is that for many mathematical concepts that appear hard to understand in written form, we can achieve some clarity by expressing the ideas in visual form. Here is my go at it.\nHere are a number of cumulative density functions for an assortment of distributions.\n\n\nCode\nnormal <- pnorm\nlogNormal <- plnorm\nexponential <- pexp\n\nggplot() + xlim(-5, 5) + \n  geom_function(fun = pnorm, colour=\"blue\") +\n  geom_function(fun = logNormal, colour=\"brown\") +\n  geom_function(fun = exponential, colour=\"purple\") +\n  labs(title=\"CDFs from an assortment of distributions\")\n\n\n\n\n\nDespite coming in every imaginable shape and size, CDFs for any function have 1 similarity. Their output (y-axis) will always be bound between 0 and 1. This makes a lot of sense when we consider that the CDF is characterised for being a monotonic increasing function. The CDF graphs the probability of \\(P(X<x)\\), given that the output is a probability, the Y axis will always be bounded between 0 and 1. This property is very useful when we match it back to the \\(Unif(0,1)\\) distribution. A uniform distribution produces random variates similarly bound between 0 and 1.\nThe last piece of the puzzle is to understand that just as a function \\(F(x)\\) can be visually described as a transformation mapping values from the X axis to values on the Y axis, and the inverse of that said function \\(F^{-1}(x)\\) is simply the inverse transformation mapping values from the Y axis to the X axis.\n\n\n\n\n\nWhat the inverse function means\n\n\n\n\nSo putting all the pieces together, this is how the Inverse Transform Theorem is put into action:\n\nThe \\(Unif(0,1)\\) distribution produces a random uniform between 0 and 1\nThis is akin to picking a random point on the Y axis of a CDF for your distribution of interest\nThe inverse function \\(F^{-1}(x)\\) maps the random uniform on the Y axis to a value on the X axis\nAnd this X axis value in turn becomes a random variate from your distribution of interest\n\n\n\nConclusion\nThe Inverse Transform Theorem is a remarkable piece of math that links the uniform distribution to just about any other distribution we could think of. It‚Äôs a crucial piece in the machinery of modern machines that enable us to run simulations, and I hope this post helps to share the visual a-ha intuition I experienced when I was learning about this topic.\n\n\n\n\n\nMidjourney AI Art with the prompt of ‚ÄòInverse Transform Theorem‚Äô\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{tan2022,\n  author = {Daniel Tan},\n  title = {Explainers: {Inverse} {Transform} {Theorem}},\n  date = {2022-08-08},\n  url = {https://www.ddanieltan.com/posts/some2},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDaniel Tan. 2022. ‚ÄúExplainers: Inverse Transform Theorem.‚Äù\nAugust 8, 2022. https://www.ddanieltan.com/posts/some2."
  },
  {
    "objectID": "posts/2022scala/index.html",
    "href": "posts/2022scala/index.html",
    "title": "2022: My Year of Scala",
    "section": "",
    "text": "What is Scala?\nScala is a programming language that is probably most famous for consistently showing up as one of the ‚ÄúTop Paying Technologies‚Äù in StackOverflow‚Äôs annual survey ü§ëü§ëü§ë. In Data Science, Scala is famous for being the language used to build the Apache Spark engine, which makes Scala essentially the core language that ‚ÄúEnterprise Big DataTM‚Äù is run on.\n// Illustrating Scala's legible syntax\n// and method chaining pattern\nval inputs = Vector(1,2,3,4,5,6,7,8)\ninputs\n    .map(x => x + 1)\n    .filter(x => x % 2 == 0)\n    .slice(2,6)\n//res1: Vector[Int] = Vector(6, 8)\nMy 1-liner description of Scala (with the caveat that I am pretty much still a beginner) is that Scala feels like a language designed for modelling and manipulating data.\nI enjoy Scala‚Äôs\n\nlegible and easy-to-read syntax\nencouraged design pattern of running an immutable data source through chains of transformations (which should be familiar to fans of Python‚Äôs method chaining or R‚Äôs pipe)\nability to give me a dynamic language experience with the safety of a compiled language\npower/scalability out-of-the-box thanks to piggy-backing on the highly optimized JVM\nunique features such as Case Classes, Implicits etc. that gives the language that extra bit of black magic to set it apart\n\n\n\nWhy Scala?\nThe main reason is that I recently joined a team where our main codebase is in Scala. This gives me a practical incentive, as well as, the opportunity to be surrounded by knowledgable colleagues who I can pester with my questions.\nThe secondary reason is curiosity. Scala is designed to support both the object-oriented paradigm and the functional programming paradigm. Through Scala, I hope to dip my toes into the great ocean that is Functional Programming.\n\n\nFingers crossed that one day, I‚Äôll be able to explain what a monad is.\n\n\nHow has the year gone so far?\nPretty good! I have not burnt out and I have found opportunities to use Scala in my projects for work, school and play. So far I have used Scala to:\n\nWrite applications to improve my tooling for work\nBuild random number generators for a module for school\nCreate a rudimentary (and incomplete) blog engine\nInch my way through the excellent Hands-on Scala book\nAutomate small scripting tasks (although I‚Äôm still not convinced Scala is my 1st choice as a scripting language)\nBuild a simple website without writing 1 line of javascript (üò≤!!) thanks to Scala.js\n\nAdditionally, I have also found small ways to engage with the small but fascinating community. For example, I enjoyed learning a little history behind Scala by asking the Reddit community What‚Äôs the story behind Scala‚Äôs logo?.\n\n\n\nMy rendition of Scala‚Äôs logo. What does this look like to you?\n\n\n\n\nEnding the year strong\nI still have a good couple of months until the end of 2022. I would like to accomplish the following before the end of this year:\n\nBuild a Scala application which serves more users than just myself\nAttempt this year‚Äôs Advent of Code in Scala\nWrite a recap blog post at the end of the year reflecting what I liked/disliked about Scala\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{tan2022,\n  author = {Daniel Tan},\n  title = {2022: {My} {Year} of {Scala}},\n  date = {2022-09-15},\n  url = {https://www.ddanieltan.com/posts/2022scala},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDaniel Tan. 2022. ‚Äú2022: My Year of Scala.‚Äù September 15,\n2022. https://www.ddanieltan.com/posts/2022scala."
  },
  {
    "objectID": "posts/stow/index.html",
    "href": "posts/stow/index.html",
    "title": "How I sync my config files with Stow",
    "section": "",
    "text": "The Big Picture\nHere is the big picture of how a Stow-enabled config synchronisation system is set up.\n\nYou will need a dotfiles version-controlled repository. The simplest approach here would be to create a Github repository\nIn dotfiles, you will create separate folders for each application‚Äôs config file you wish to keep in sync. What you name these folders is totally up to you, but conventionally most people name the folder after the application\n\nFor example, a simple dotfiles repo might look like this.\n.\n‚îú‚îÄ‚îÄ aliases\n‚îú‚îÄ‚îÄ kitty\n‚îî‚îÄ‚îÄ nvim\nHere, I intend to sync my shell aliases, terminal configs (Kitty) and editor configs (NeoVim), so I create a separate folder for each.\n\nWithin each folder, you can create the config files that we want to be kept in-sync\nUsing Stow, you can then create a symlink of these config files which would be placed in the right locations on your file system for the respective applications to read from\nOnce this is set up, the day-to-day usage of this system is incredibly simple. Any time you make make edits to your config files on 1 machine, you simply need to commit and push the changes made in your dotfiles repo. Your config files are symlink-ed to the files in your dotfiles repo, and any edit you make will be updated. Next time you hop into a different machine, just pull down the latest changes in the dotfiles repo and all your configs will be updated\n\nSteps 3 and 4 are the tricky bits and I provide a more detailed example of them below.\n\n\nSyncing a config file for the 1st time\nHere is an example scenario. I have 2 machines (A and B), and I want to sync the configurations for the terminal application, e.g.¬†the Kitty terminal. To configure this terminal, you would edit a config file kitty.conf whose default location is ~/.config/kitty/kitty.conf. Here is what you would do:\n\n\nYes, I see the irony in using Kitty because it is a GPU-accelerated application whose primary function is to print out text‚Ä¶\n\nWe start from machine A. Firstly, you will need to delete the existing kitty.conf file\nIn your dotfiles repo, within the kitty folder, create a new kitty.conf file but make sure this file is in the same folder structure of the default config location. I.e. your new config file should sit in the dotfiles repo like this\n\n.\n‚îú‚îÄ‚îÄ aliases\n‚îú‚îÄ‚îÄ kitty\n‚îÇ   ‚îî‚îÄ‚îÄ .config\n‚îÇ       ‚îî‚îÄ‚îÄ kitty\n‚îÇ           ‚îî‚îÄ‚îÄ kitty.conf\n‚îî‚îÄ‚îÄ nvim\n\nFill up kitty.conf with your desired settings\nNavigate back up to the dotfiles repo and run stow kitty. This command will create a symlink of the contents of the kitty folder, which will create a kitty.conf in the ~/.config/kitty/kitty.conf location\nWe are done setting up on Machine A. Commit and push the changes to your dotfiles repo\nFinally, log into Machine B. Pull down the changes and because we have not run stow in this machine, you will need to run stow kitty here too to create the symlinks.\n\nStow is something you only need to run the 1st time you add a config file. You do not have to run stow for any subsequent edits.\n\n\nLimitations\nThis config sync system is pretty sweet but it is not without some limitations. Here is a couple for you to be aware of.\nStowing too many config files can also get out of hand pretty quickly. You probably want to consider which applications you are genuinely using often enough across multiple machines, just so you avoid creating obsolete symlinks.\nAdditionally, there are some situations where you do not want config files synced. For example, I do not use this system to sync my shell configs because my shell configs might contain sensitive environment variables or have settings unique to the type of hardware the software is running on.\n\n\nConclusions\n\n‚ÄúLife truly begins when you put your house in order.‚Äù - Marie Kondo\n\nCouldn‚Äôt have phrased it better myself! Stow is a great tool to keep your config files sync-ed, do give it a try.\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{tan2022,\n  author = {Daniel Tan},\n  title = {How {I} Sync My Config Files with {Stow}},\n  date = {2022-08-27},\n  url = {https://www.ddanieltan.com/posts/stow},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDaniel Tan. 2022. ‚ÄúHow I Sync My Config Files with Stow.‚Äù\nAugust 27, 2022. https://www.ddanieltan.com/posts/stow."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ü§î",
    "section": "",
    "text": "How I added a new tool to my toolbox\n\n\n\n\n\n\nSeptember 15, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nA simple system to keep chaos at bay\n\n\n\n\n\n\nAugust 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nA #SoME2 submission\n\n\n\n\n\n\nAugust 8, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nA new hope\n\n\n\n\n\n\nJuly 15, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Daniel Tan",
    "section": "",
    "text": "I currently work on Experimentation @Apple. Previously, I worked on Personalisation @OCBC AI Labs and on the metasearch auction @TripAdvisor.\nOcassionally, I teach data science workshops @General Assembly and @Vertical Institute."
  }
]